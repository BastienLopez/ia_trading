# Bibliothèques d'analyse de données
numpy>=1.23.5,<2.0.0
pandas>=2.0.0
matplotlib>=3.5.0
seaborn>=0.12.2
scikit-learn>=1.2.0
scipy>=1.7.0
statsmodels>=0.13.0
python-dateutil>=2.8.2
pytz>=2021.1

# Trading et analyse technique
ccxt>=4.2.0
ta>=0.10.0
# TA-Lib est installé séparément via apt/brew ou le script d'installation

# Apprentissage par renforcement
# TensorFlow compatible avec les deux plateformes (Linux et Windows)
# Pour Linux: TensorFlow 2.12+ supporte bien les fonctionnalités avancées
# Pour Windows: TensorFlow 2.15+ recommandé pour une meilleure stabilité
tensorflow>=2.12.0
tensorflow_probability>=0.23.0
# Keras avec compatibilité multiplateforme
keras>=2.12.0
# tf-keras est nécessaire pour tensorflow_probability avec TensorFlow
tf-keras>=2.12.0
gymnasium>=0.29.1
stable-baselines3>=2.2.1
torch>=2.0.0
optuna>=3.0.0
packaging>=23.0
jax>=0.4.14
# ray[rllib,tune]==2.45.0  # Commenté en raison de problèmes d'installation sur Windows

# Optimisations CPU/GPU
psutil>=7.0.0
pyarrow>=15.0.0
h5py>=3.10.0
threadpoolctl>=3.1.0
pympler>=1.0.1
py-spy>=0.3.14
line_profiler>=4.1.1
numba>=0.61.0
bottleneck>=1.4.0
memory_profiler>=0.61.0
fastparquet>=2023.0.0
# Accelerate - crucial pour la gestion des modèles entre CPU et GPU
accelerate>=0.24.0

# Compression et traitement d'image
zstandard>=0.20.0
opencv-python>=4.8.0
opencv-python-headless>=4.8.0

# Packages optionnels (installation séparée si besoin)
# -----------------------------------------------------
# DeepSpeed (difficile à installer sur Windows)
# Pour installer DeepSpeed sur Linux : pip install deepspeed>=0.12.0
# Pour Windows, il faut d'abord installer Visual C++ Build Tools et CUDA :
#   1. Installer Visual Studio Build Tools avec "Desktop development with C++"
#   2. Installer CUDA Toolkit (compatible avec votre version de PyTorch)
#   3. Exécuter: pip install deepspeed
# Si l'installation échoue sur Windows, ne vous inquiétez pas - le module ai_trading/utils/deepspeed_optimizer.py 
# contient une implémentation de compatibilité qui simule l'API DeepSpeed pour les tests et la formation.

# Ray (peut causer des problèmes d'installation sur Windows)
# Pour installer Ray sur Linux : pip install ray[rllib,tune]>=2.45.0
# Pour Windows, utilisez l'installation manuelle ou le wrapper de compatibilité

# Exportation et optimisation de modèles
onnx>=1.15.0
onnxruntime>=1.16.0
onnxruntime-gpu>=1.16.0  # Support GPU pour ONNX Runtime
tf2onnx>=1.15.0
hyperopt>=0.2.7
bayesian-optimization>=1.4.3

# API et collecte de données
requests>=2.31.0
pycoingecko>=3.0.0
beautifulsoup4>=4.12.3
tweepy>=4.14.0
praw>=7.7.1
newsapi-python>=0.2.7

# Traitement du langage naturel
nltk>=3.8.1
textblob>=0.17.1
transformers>=4.35.0
sentence-transformers>=2.2.2
emoji>=2.8.0
spacy>=3.7.0
huggingface-hub>=0.20.0
xformers>=0.0.23

# Web et API
flask>=2.3.3
jinja2>=3.1.2
werkzeug>=2.3.7
itsdangerous>=2.1.2
flask-wtf>=1.1.1
flask-login>=0.6.2
flask-cors>=4.0.0
flask-socketio>=5.3.6
python-socketio>=5.11.2
websocket-client>=1.7.0
fastapi>=0.115.0
uvicorn>=0.27.1
starlette>=0.38.6
httpx>=0.27.0

# Visualisation
plotly>=5.3.0
dash>=2.0.0

# Tests et développement
pytest>=7.0.0
pytest-cov>=6.1.0
pytest-sugar>=0.9.7
pytest-timeout>=2.1.0
pytest-repeat>=0.9.1
pytest-mock>=3.14.0
pytest-xdist>=3.3.1
pytest-benchmark>=4.0.0  # Pour les benchmarks de performance
pytest-profiling>=1.7.0  # Pour le profilage du code pendant les tests
black>=23.0.0
isort>=5.12.0
autoflake>=2.2.0
jupyter>=1.0.0

# Utilitaires
tqdm>=4.66.1
joblib>=1.3.0
python-dotenv>=1.0.0
importlib-metadata>=6.0.0
pillow>=10.2.0

# ML avancé
xgboost>=2.0.0
lightgbm>=4.1.0
arch>=6.0.0

# Support CUDA et optimisations hardware-specific
# Ces packages ne sont pas installés automatiquement car ils dépendent de la configuration matérielle
# torch-tensorrt  # Optimisation TensorRT pour PyTorch (s'installe séparément)
# cupy-cuda11x  # Remplacer 11x par votre version CUDA (10.2, 11.x, 12.x)

# Dépendances pour la collecte asynchrone
aiohttp>=3.8.0
redis>=4.0.0
tenacity>=8.0.0
pytest>=6.2.0
pytest-asyncio>=0.16.0
pytest-mock>=3.6.0
